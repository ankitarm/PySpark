{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNsC2ys22DB18h4q5xaHz1P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ankitarm/PySpark/blob/main/Spark_Reading_files.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text files"
      ],
      "metadata": {
        "id": "2sUgSzEb46Dm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ".text('path', , lineSep = \"||\",  wholetext=True).option(\"encoding\" , \"UTF-8\")"
      ],
      "metadata": {
        "id": "leBsZgoei7Cd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cN6K8Ef4mKx",
        "outputId": "714bc11e-f242-4038-d304-31e483e852c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+\n",
            "|             value|\n",
            "+------------------+\n",
            "|name||address||age|\n",
            "+------------------+\n",
            "\n",
            "+------------------+\n",
            "|             value|\n",
            "+------------------+\n",
            "|name||address||age|\n",
            "|name||address||age|\n",
            "+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"Textfiles\").getOrCreate()\n",
        "data1 = spark.read.text(\"/content/textfile1.txt\")\n",
        "data1.show()\n",
        "\n",
        "data2 = spark.read.text(\"/content/textfile2.txt\")\n",
        "data2.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data3 = spark.read.option(\"lineSep\",\"||\").text(\"/content/textfile1.txt\")\n",
        "data3.show()\n",
        "data4 = spark.read.option(\"lineSep\",\"||\").text(\"/content/textfile2.txt\")\n",
        "data4.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RGWq11a6dCV",
        "outputId": "c13c9ed0-4ce0-44c2-dca6-903256439188"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+\n",
            "|  value|\n",
            "+-------+\n",
            "|   name|\n",
            "|address|\n",
            "|    age|\n",
            "+-------+\n",
            "\n",
            "+-----------+\n",
            "|      value|\n",
            "+-----------+\n",
            "|       name|\n",
            "|    address|\n",
            "|age\\r\\nname|\n",
            "|    address|\n",
            "|        age|\n",
            "+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can write in .option() like above or within text() like below"
      ],
      "metadata": {
        "id": "bIMeUWoO95pd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data5 = spark.read.text(\"/content/textfile1.txt\", lineSep = \"||\")\n",
        "data5.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iF55rUob8GFR",
        "outputId": "046d1340-dea8-42ff-c313-144f840a0872"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+\n",
            "|  value|\n",
            "+-------+\n",
            "|   name|\n",
            "|address|\n",
            "|    age|\n",
            "+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "UTF-8 (default), ISO-8859-1, or latin1"
      ],
      "metadata": {
        "id": "pAJPjHD6-Tpy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want to specify encoding (like UTF-8, ISO-8859-1, etc.), you should use the option() method with the key \"encoding\" because spark.read.text() does not support the encoding parameter directly."
      ],
      "metadata": {
        "id": "YFfkR-46BGjy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data7 = spark.read.option(\"lineSep\",\"||\").option(\"encoding\" , \"UTF-8\").text(\"/content/textfile1.txt\")\n",
        "data7.show()\n",
        "data6 = spark.read.text(\"/content/textfile1.txt\", lineSep = \"||\", encoding = \"UTF-8\")\n",
        "data6.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "hJZ06xkm9ylO",
        "outputId": "570f5df0-ba17-44b4-e400-ea981abdcde0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+\n",
            "|  value|\n",
            "+-------+\n",
            "|   name|\n",
            "|address|\n",
            "|    age|\n",
            "+-------+\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "DataFrameReader.text() got an unexpected keyword argument 'encoding'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-2764315520>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata7\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"lineSep\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"||\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding\"\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m\"UTF-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/textfile1.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdata7\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdata6\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/textfile1.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlineSep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"||\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"UTF-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdata6\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: DataFrameReader.text() got an unexpected keyword argument 'encoding'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below doesnt show desired output as it should read entire file in a line. So .option() doesn't work."
      ],
      "metadata": {
        "id": "T4V-UzpI_nWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data8 = spark.read.option(\"wholetext\",True).text(\"/content/textfile2.txt\")\n",
        "data8.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBPj_HpM-6mF",
        "outputId": "76c4dfea-02be-462d-e84e-f2bbd2ff8d58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+\n",
            "|             value|\n",
            "+------------------+\n",
            "|name||address||age|\n",
            "|name||address||age|\n",
            "+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data9 = spark.read.wholeTextFiles(\"/content/textfile2.txt\")\n",
        "data9.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "p0igoWIsAHdr",
        "outputId": "dfa28f82-4ed8-46cb-b5b5-04a67729ac26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'DataFrameReader' object has no attribute 'wholeTextFiles'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-2396447637>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata9\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwholeTextFiles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/textfile2.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata9\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'DataFrameReader' object has no attribute 'wholeTextFiles'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "wholetext works as below\n"
      ],
      "metadata": {
        "id": "zaeAngxuCGAi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data10 = spark.read.text(\"/content/textfile2.txt\", wholetext=True)\n",
        "data10.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dD0ySmsRAn0T",
        "outputId": "de3f2f37-6cbb-4cda-d12f-5cf8f3552dfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------------------+\n",
            "|value                                   |\n",
            "+----------------------------------------+\n",
            "|name||address||age\\r\\nname||address||age|\n",
            "+----------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hXGXf_zJCcub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*italicized text*# New Section"
      ],
      "metadata": {
        "id": "OycNFG2GqnuO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CSV files\n"
      ],
      "metadata": {
        "id": "q9m7hqfHjeZ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df4 = spark.read.options(delimiter=\";\", header=True).csv(path)"
      ],
      "metadata": {
        "id": "RBscl3Asq-uw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Json files"
      ],
      "metadata": {
        "id": "EMDVVxDtqrix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "peopleDF = spark.read.json(path)\n",
        "\n",
        "#rdds\n",
        "#parallelise and then pass in json\n",
        "sc = spark.sparkContext\n",
        "jsonStrings = ['{\"name\":\"Yin\",\"address\":{\"city\":\"Columbus\",\"state\":\"Ohio\"}}']\n",
        "otherPeopleRDD = sc.parallelize(jsonStrings)\n",
        "otherPeople = spark.read.json(otherPeopleRDD)\n",
        "otherPeople.show()\n",
        "\n",
        "\n",
        "# Read the multiline JSON\n",
        "df = spark.read.option(\"multiline\", \"true\").json(\"path/to/data.json\")"
      ],
      "metadata": {
        "id": "cu8sRuvWlaFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "{\n",
        "  \"id\": 1,\n",
        "  \"name\": \"Alice\",\n",
        "  \"location\": {\n",
        "    \"city\": \"Austin\",\n",
        "    \"state\": \"TX\"\n",
        "  }\n",
        "}\n"
      ],
      "metadata": {
        "id": "h7GFPiMApE3S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data11 = spark.read.option(\"multiline\", \"true\").json(\"/content/json1.json\")\n",
        "data11.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wcABtLVoGzM",
        "outputId": "5e003cbc-6ebd-4122-8812-44e8c872c9db"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------------+-----+\n",
            "|id |location    |name |\n",
            "+---+------------+-----+\n",
            "|1  |{Austin, TX}|Alice|\n",
            "+---+------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Different ways to read json\n",
        "\n",
        "1.   df = spark.read.json(\"path/to/file.json\")\n",
        "2.   df = spark.read.format(\"json\").load(\"path/to/file.json\")\n",
        "3.   df = spark.read.option(\"multiLine\", True).json(\"path/to/multiline.json\")\n",
        "4.   df = spark.read.json(\"path/to/files/*.json\")\n",
        "5.   rdd = sc.parallelize(['{\"name\":\"John\", \"age\":30}', '{\"name\":\"Alice\", \"age\":25}'])\n",
        "df = spark.read.json(rdd)\n",
        "6.   If a column contains JSON strings, you can parse them using from_json.\n",
        "7.   Read stream stream_df = spark.readStream.schema(schema).json(\"path/to/json_stream\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VVMVhgIGrQPG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AmGlw2B6pOoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*italicized text*# New Section"
      ],
      "metadata": {
        "id": "6WZGxYMhqbqu"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-9Cf6FAToYaN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}